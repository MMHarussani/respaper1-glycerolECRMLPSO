{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1XNmy1Sgfg9DhkjP97v0pNTSRZJs-Bd2A","authorship_tag":"ABX9TyN580ad9dI0YZ6NaBUke0Q6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#improved version always second\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","from math import sqrt\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import r2_score\n","\n","path = \"/content/drive/MyDrive/dataset/raw data.csv\"\n","data = pd.read_csv(path)\n","\n","data = pd.get_dummies(data) #convert categorical variable into dummy variable\n","\n","y = np.array(data['CR (%)']) #output feature\n","X = data.drop(['CR (%)', 'ECR PY (%)', 'PDOs PY (%)', 'POHs PY (%)', 'V'], axis=1) #input feature - axis=1 refers to the column\n","\n","X_list = list(X.columns) # Saving feature names for later use\n","\n","from sklearn.preprocessing import StandardScaler #standardscaler for normalization (Jinesh et al., 2023)\n","scaler = StandardScaler()\n","\n","y = y.reshape(-1, 1) #normalizing y\n","scaler.fit(y)\n","y = scaler.transform(y)\n","\n","scaler.fit(X) #normalizing X\n","X = scaler.transform(X)\n","\n","X = np.array(X) # Convert to numpy array\n","\n","# Using Skicit-learn to split data into training and testing sets\n","from sklearn.model_selection import train_test_split\n","\n","# Split the data into training and testing sets\n","train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42)\n","print('Training X Shape:', train_X.shape)\n","print('Training y Shape:', train_y.shape)\n","print('Testing X Shape:', test_X.shape)\n","print('Testing y Shape:', test_y.shape)\n","\n","#imputation for missing value using kNN algo\n","from sklearn.impute import KNNImputer\n","\n","imputer = KNNImputer(n_neighbors=10) #create an instance of KNNImputer class, k is desired number of neighbours\n","\n","#perform imputation on on X because y no missing values\n","imp_train_X = imputer.fit_transform(train_X)\n","imp_test_X = imputer.fit_transform(test_X)\n","\n","#random forest regression\n","model = RandomForestRegressor(n_estimators=100, random_state=0)\n","model.fit(imp_train_X, train_y)\n","preds = model.predict(imp_test_X)\n","\n","score = model.score(imp_train_X,train_y)\n","print(\"Training score: \", score)\n","\n","pred = model.predict(imp_test_X)\n","\n","print(\"Mean Absolute Error: \" + str(mean_absolute_error(test_y, pred)))\n","print(\"MSE: \" + str(mean_squared_error(preds, test_y)))\n","\n","RMSE = sqrt(mean_squared_error(preds, test_y))\n","\n","print(\"RMSE: \" + str(RMSE))\n","print(\"R2 score: \" + str(r2_score(test_y, preds)))\n","\n"],"metadata":{"id":"HLNvMg-DabmV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706102076668,"user_tz":-540,"elapsed":3484,"user":{"displayName":"Muhd Harussani","userId":"10681559320848216583"}},"outputId":"21a2e28d-996b-45f5-aa01-66b2df76aa91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training X Shape: (312, 30)\n","Training y Shape: (312, 1)\n","Testing X Shape: (134, 30)\n","Testing y Shape: (134, 1)\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-1-b14147c3db0f>:56: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(imp_train_X, train_y)\n"]},{"output_type":"stream","name":"stdout","text":["Training score:  0.9927064263513695\n","Mean Absolute Error: 0.140841472346795\n","MSE: 0.05459088841183673\n","RMSE: 0.23364693109869158\n","R2 score: 0.947866849777909\n"]}]},{"cell_type":"code","source":["#gridsearch here we go!\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","from math import sqrt\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import r2_score\n","\n","path = \"/content/drive/MyDrive/dataset/raw data.csv\"\n","data = pd.read_csv(path)\n","\n","data = pd.get_dummies(data) #convert categorical variable into dummy variable\n","\n","y = np.array(data['PDOs PY (%)']) #output feature\n","X = data.drop(['CR (%)', 'PDOs PY (%)', 'I (A)'], axis=1) #input feature - axis=1 refers to the column\n","\n","X_list = list(X.columns) # Saving feature names for later use\n","\n","from sklearn.preprocessing import StandardScaler #standardscaler for normalization (Jinesh et al., 2023)\n","scaler = StandardScaler()\n","\n","y = y.reshape(-1, 1) #normalizing y\n","scaler.fit(y)\n","y = scaler.transform(y)\n","\n","scaler.fit(X) #normalizing X\n","X = scaler.transform(X)\n","\n","X = np.array(X) # Convert to numpy array\n","\n","# Using Skicit-learn to split data into training and testing sets\n","from sklearn.model_selection import train_test_split\n","\n","# Split the data into training and testing sets\n","train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42)\n","print('Training X Shape:', train_X.shape)\n","print('Training y Shape:', train_y.shape)\n","print('Testing X Shape:', test_X.shape)\n","print('Testing y Shape:', test_y.shape)\n","\n","#imputation for missing value using kNN algo\n","from sklearn.impute import KNNImputer\n","\n","imputer = KNNImputer(n_neighbors=10) #create an instance of KNNImputer class, k is desired number of neighbours\n","\n","#perform imputation on on X because y no missing values\n","imp_train_X = imputer.fit_transform(train_X)\n","imp_test_X = imputer.fit_transform(test_X)\n","\n","#hyperparamter optimization using gridsearch\n","from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n","random_cv = GridSearchCV(\n","            estimator=RandomForestRegressor(),\n","            param_grid={'n_estimators': [100, 200, 500],\n","                        'max_depth': [None, 3, 6],\n","                        'min_samples_split': [2, 4, 6],\n","                        'min_samples_leaf': [1, 2, 3],\n","                        #'max_features': ['auto', 'sqrt'],\n","                        'random_state': [0, 42]},\n","            cv=3, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n","#This includes 3-fold validation (cv=3) and uses mean scare error as the metric for evaluation\n","\n","random_cv.fit(imp_train_X, train_y)\n","\n","# use the best parameters\n","best_params = random_cv.best_params_\n","best_score = random_cv.best_score_\n","print('Best hyperparameters:', best_params)\n","\n","# using the best parameters run model\n","model = RandomForestRegressor(**best_params)\n","model.fit(imp_train_X, train_y)\n","\n","score = model.score(imp_train_X,train_y)\n","print(\"Training score: \", score)\n","\n","pred = model.predict(imp_test_X)\n","\n","print(\"Mean Absolute Error: \" + str(mean_absolute_error(test_y, pred)))\n","print(\"MSE: \" + str(mean_squared_error(pred, test_y)))\n","\n","RMSE = sqrt(mean_squared_error(pred, test_y))\n","\n","print(\"RMSE: \" + str(RMSE))\n","print(\"R2 score: \" + str(r2_score(test_y, pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UnHX8DmAh3jR","executionInfo":{"status":"ok","timestamp":1705304474971,"user_tz":-540,"elapsed":218735,"user":{"displayName":"Muhd Harussani","userId":"10681559320848216583"}},"outputId":"cbf51d86-1ca5-4d7c-b7b9-8ca2e16ded6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training X Shape: (312, 30)\n","Training y Shape: (312, 1)\n","Testing X Shape: (134, 30)\n","Testing y Shape: (134, 1)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:909: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  self.best_estimator_.fit(X, y, **fit_params)\n","<ipython-input-9-8d53a7643c58>:76: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  model.fit(imp_train_X, train_y)\n"]},{"output_type":"stream","name":"stdout","text":["Best hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100, 'random_state': 0}\n","Training score:  0.9671767585181567\n","Mean Absolute Error: 0.18966454511737257\n","MSE: 0.24517088356032346\n","RMSE: 0.495147335204708\n","R2 score: 0.7823250204884203\n"]}]},{"cell_type":"code","source":["#improved version always second (PDOs PY)\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","from math import sqrt\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import r2_score\n","\n","path = \"/content/drive/MyDrive/dataset/raw data.csv\"\n","data = pd.read_csv(path)\n","\n","data = pd.get_dummies(data) #convert categorical variable into dummy variable\n","\n","y = np.array(data['PDOs PY (%)']) #output feature\n","X = data.drop(['CR (%)', 'ECR PY (%)', 'PDOs PY (%)', 'POHs PY (%)', 'V'], axis=1) #input feature - axis=1 refers to the column\n","\n","X_list = list(X.columns) # Saving feature names for later use\n","\n","from sklearn.preprocessing import StandardScaler #standardscaler for normalization (Jinesh et al., 2023)\n","scaler = StandardScaler()\n","\n","y = y.reshape(-1, 1) #normalizing y\n","scaler.fit(y)\n","y = scaler.transform(y)\n","\n","scaler.fit(X) #normalizing X\n","X = scaler.transform(X)\n","\n","X = np.array(X) # Convert to numpy array\n","\n","# Using Skicit-learn to split data into training and testing sets\n","from sklearn.model_selection import train_test_split\n","\n","# Split the data into training and testing sets\n","train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42)\n","print('Training X Shape:', train_X.shape)\n","print('Training y Shape:', train_y.shape)\n","print('Testing X Shape:', test_X.shape)\n","print('Testing y Shape:', test_y.shape)\n","\n","#imputation for missing value using kNN algo\n","from sklearn.impute import KNNImputer\n","\n","imputer = KNNImputer(n_neighbors=10) #create an instance of KNNImputer class, k is desired number of neighbours\n","\n","#perform imputation on on X because y no missing values\n","imp_train_X = imputer.fit_transform(train_X)\n","imp_test_X = imputer.fit_transform(test_X)\n","\n","#random forest regression\n","model = RandomForestRegressor(max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100, random_state=0)\n","model.fit(imp_train_X, train_y)\n","preds = model.predict(imp_test_X)\n","\n","score = model.score(imp_train_X,train_y)\n","print(\"Training score: \", score)\n","\n","pred = model.predict(imp_test_X)\n","\n","print(\"Mean Absolute Error: \" + str(mean_absolute_error(test_y, pred)))\n","print(\"MSE: \" + str(mean_squared_error(preds, test_y)))\n","\n","RMSE = sqrt(mean_squared_error(preds, test_y))\n","\n","print(\"RMSE: \" + str(RMSE))\n","print(\"R2 score: \" + str(r2_score(test_y, preds)))\n","\n"],"metadata":{"id":"hvpImkc3Dflg"},"execution_count":null,"outputs":[]}]}