{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"15s2pHV7_NylVCmXvHC_PAr2c7JMRFFrT","authorship_tag":"ABX9TyPChau2EkWbBbaF39tMDj5z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#improved version always second (normalized for SVM)\n","\n","from math import sqrt\n","import pandas as pd\n","import numpy as np\n","import os\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import r2_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn import svm\n","from sklearn.svm import SVR\n","\n","path = \"/content/drive/MyDrive/dataset/raw data.csv\"\n","data = pd.read_csv(path)\n","\n","data = pd.get_dummies(data) #convert categorical variable into dummy variable\n","\n","y = np.array(data['CR (%)']) #output feature\n","X = data.drop(['CR (%)', 'ECR PY (%)', 'PDOs PY (%)', 'POHs PY (%)', 'V'], axis=1) #input feature - axis=1 refers to the column\n","\n","X_list = list(X.columns) # Saving feature names for later use\n","\n","from sklearn.preprocessing import StandardScaler #standardscaler for normalization (Jinesh et al., 2023)\n","scaler = StandardScaler()\n","\n","y = y.reshape(-1, 1) #normalizing y\n","scaler.fit(y)\n","y = scaler.transform(y)\n","\n","scaler.fit(X) #normalizing X\n","X = scaler.transform(X)\n","\n","X = np.array(X) # Convert to numpy array\n","\n","# Using Skicit-learn to split data into training and testing sets\n","from sklearn.model_selection import train_test_split\n","\n","# Split the data into training and testing sets\n","train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42)\n","print('Training X Shape:', train_X.shape)\n","print('Training y Shape:', train_y.shape)\n","print('Testing X Shape:', test_X.shape)\n","print('Testing y Shape:', test_y.shape)\n","\n","#imputation for missing value using kNN algo\n","from sklearn.impute import KNNImputer\n","\n","imputer = KNNImputer(n_neighbors=10) #create an instance of KNNImputer class, k is desired number of neighbours\n","\n","#perform imputation on on X because y no missing values\n","imp_train_X = imputer.fit_transform(train_X)\n","imp_test_X = imputer.fit_transform(test_X)\n","\n","#start SVM regression modelling\n","model = SVR(C=10, gamma='scale', kernel='rbf')\n","model.fit(imp_train_X, train_y)\n","\n","score = model.score(imp_train_X,train_y)\n","print(\"Training score: \", score)\n","\n","pred = model.predict(imp_test_X)\n","\n","print(\"Mean Absolute Error: \" + str(mean_absolute_error(test_y, pred)))\n","print(\"MSE: \" + str(mean_squared_error(pred, test_y)))\n","\n","RMSE = sqrt(mean_squared_error(pred, test_y))\n","\n","print(\"RMSE: \" + str(RMSE))\n","print(\"R2 score: \" + str(r2_score(test_y, pred)))"],"metadata":{"id":"gCFhspRmWol3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706102205411,"user_tz":-540,"elapsed":3343,"user":{"displayName":"Muhd Harussani","userId":"10681559320848216583"}},"outputId":"cc0589c5-dd72-41c3-8119-c41a4ba2ed71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training X Shape: (312, 30)\n","Training y Shape: (312, 1)\n","Testing X Shape: (134, 30)\n","Testing y Shape: (134, 1)\n","Training score:  0.9647602128357118\n","Mean Absolute Error: 0.1370976312397405\n","MSE: 0.03685290499087797\n","RMSE: 0.19197110457274025\n","R2 score: 0.9648062508615759\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}]},{"cell_type":"code","source":["#next, gridsearch for hyperparameter optimixation\n","\n","from math import sqrt\n","import pandas as pd\n","import numpy as np\n","import os\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import r2_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn import svm\n","from sklearn.svm import SVR\n","\n","path = \"/content/drive/MyDrive/dataset/raw data.csv\"\n","data = pd.read_csv(path)\n","\n","data = pd.get_dummies(data) #convert categorical variable into dummy variable\n","\n","y = np.array(data['PDOs PY (%)']) #output feature\n","X = data.drop(['CR (%)', 'PDOs PY (%)', 'I (A)'], axis=1) #input feature - axis=1 refers to the column\n","\n","X_list = list(X.columns) # Saving feature names for later use\n","\n","from sklearn.preprocessing import StandardScaler #standardscaler for normalization (Jinesh et al., 2023)\n","scaler = StandardScaler()\n","\n","y = y.reshape(-1, 1) #normalizing y\n","scaler.fit(y)\n","y = scaler.transform(y)\n","\n","scaler.fit(X) #normalizing X\n","X = scaler.transform(X)\n","\n","X = np.array(X) # Convert to numpy array\n","\n","# Using Skicit-learn to split data into training and testing sets\n","from sklearn.model_selection import train_test_split\n","\n","# Split the data into training and testing sets\n","train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42)\n","print('Training X Shape:', train_X.shape)\n","print('Training y Shape:', train_y.shape)\n","print('Testing X Shape:', test_X.shape)\n","print('Testing y Shape:', test_y.shape)\n","\n","#imputation for missing value using kNN algo\n","from sklearn.impute import KNNImputer\n","\n","imputer = KNNImputer(n_neighbors=10) #create an instance of KNNImputer class, k is desired number of neighbours\n","\n","#perform imputation on on X because y no missing values\n","imp_train_X = imputer.fit_transform(train_X)\n","imp_test_X = imputer.fit_transform(test_X)\n","\n","#hyperparamter optimization using gridsearch\n","from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n","random_cv = GridSearchCV(\n","            estimator=SVR(),\n","            param_grid={'C': [0.1, 1, 10],\n","                        'kernel': ['linear', 'rbf', 'poly'],\n","                        'gamma': ['scale', 'auto']},\n","            cv=3, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n","#This includes 3-fold validation (cv=3) and uses mean scare error as the metric for evaluation\n","\n","random_cv.fit(imp_train_X,train_y)\n","\n","# use the best parameters\n","best_params = random_cv.best_params_\n","best_score = random_cv.best_score_\n","print('\\n Best hyperparameters:', best_params)\n","\n","# using the best parameters run XGBoost\n","model = SVR(**best_params)\n","model.fit(imp_train_X, train_y)\n","\n","score = model.score(imp_train_X,train_y)\n","print(\"Training score: \", score)\n","\n","pred = model.predict(imp_test_X)\n","\n","print(\"Mean Absolute Error: \" + str(mean_absolute_error(test_y, pred)))\n","print(\"MSE: \" + str(mean_squared_error(pred, test_y)))\n","\n","RMSE = sqrt(mean_squared_error(pred, test_y))\n","\n","print(\"RMSE: \" + str(RMSE))\n","print(\"R2 score: \" + str(r2_score(test_y, pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FNg6fxM_b-ls","executionInfo":{"status":"ok","timestamp":1705304729934,"user_tz":-540,"elapsed":8106,"user":{"displayName":"Muhd Harussani","userId":"10681559320848216583"}},"outputId":"fa9583db-80a5-4908-d6bd-dff444b2fb64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training X Shape: (312, 30)\n","Training y Shape: (312, 1)\n","Testing X Shape: (134, 30)\n","Testing y Shape: (134, 1)\n","\n"," Best hyperparameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n","Training score:  0.7491333259681967\n","Mean Absolute Error: 0.32241889373296806\n","MSE: 0.5272046336802155\n","RMSE: 0.7260885852843408\n","R2 score: 0.5319213433167946\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}]},{"cell_type":"code","source":["###########improved version always second (normalized for SVM) - PDOs PY\n","\n","from math import sqrt\n","import pandas as pd\n","import numpy as np\n","import os\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import r2_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn import svm\n","from sklearn.svm import SVR\n","\n","path = \"/content/drive/MyDrive/dataset/raw data.csv\"\n","data = pd.read_csv(path)\n","\n","data = pd.get_dummies(data) #convert categorical variable into dummy variable\n","\n","y = np.array(data['PDOs PY (%)']) #output feature\n","X = data.drop(['CR (%)', 'ECR PY (%)', 'PDOs PY (%)', 'POHs PY (%)', 'V'], axis=1) #input feature - axis=1 refers to the column\n","\n","X_list = list(X.columns) # Saving feature names for later use\n","\n","from sklearn.preprocessing import StandardScaler #standardscaler for normalization (Jinesh et al., 2023)\n","scaler = StandardScaler()\n","\n","y = y.reshape(-1, 1) #normalizing y\n","scaler.fit(y)\n","y = scaler.transform(y)\n","\n","scaler.fit(X) #normalizing X\n","X = scaler.transform(X)\n","\n","X = np.array(X) # Convert to numpy array\n","\n","# Using Skicit-learn to split data into training and testing sets\n","from sklearn.model_selection import train_test_split\n","\n","# Split the data into training and testing sets\n","train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42)\n","print('Training X Shape:', train_X.shape)\n","print('Training y Shape:', train_y.shape)\n","print('Testing X Shape:', test_X.shape)\n","print('Testing y Shape:', test_y.shape)\n","\n","#imputation for missing value using kNN algo\n","from sklearn.impute import KNNImputer\n","\n","imputer = KNNImputer(n_neighbors=10) #create an instance of KNNImputer class, k is desired number of neighbours\n","\n","#perform imputation on on X because y no missing values\n","imp_train_X = imputer.fit_transform(train_X)\n","imp_test_X = imputer.fit_transform(test_X)\n","\n","#start SVM regression modelling\n","model = SVR(C=10, gamma='scale', kernel='rbf')\n","model.fit(imp_train_X, train_y)\n","\n","score = model.score(imp_train_X,train_y)\n","print(\"Training score: \", score)\n","\n","pred = model.predict(imp_test_X)\n","\n","print(\"Mean Absolute Error: \" + str(mean_absolute_error(test_y, pred)))\n","print(\"MSE: \" + str(mean_squared_error(pred, test_y)))\n","\n","RMSE = sqrt(mean_squared_error(pred, test_y))\n","\n","print(\"RMSE: \" + str(RMSE))\n","print(\"R2 score: \" + str(r2_score(test_y, pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-frxxw3nE8sI","executionInfo":{"status":"ok","timestamp":1714976347727,"user_tz":-540,"elapsed":3017,"user":{"displayName":"Muhd Harussani","userId":"10681559320848216583"}},"outputId":"eab75ed9-ad87-422a-c701-cf2650c82292"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training X Shape: (312, 30)\n","Training y Shape: (312, 1)\n","Testing X Shape: (134, 30)\n","Testing y Shape: (134, 1)\n","Training score:  0.7486111293783513\n","Mean Absolute Error: 0.31810491078925895\n","MSE: 0.5271120298601905\n","RMSE: 0.7260248135292556\n","R2 score: 0.5320035616223858\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}]}]}