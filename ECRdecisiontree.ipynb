{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1LAE0oIKBAqqWMoXoh1oSMcUq1GQpx2Sj","authorship_tag":"ABX9TyMpFthFexYS0OkN3iCDlsf0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["############improved version always second\n","import pandas as pd\n","import numpy as np\n","from math import sqrt\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.metrics import r2_score\n","\n","path = \"/content/drive/MyDrive/dataset/raw data.csv\"\n","data = pd.read_csv(path)\n","\n","data = pd.get_dummies(data) #convert categorical variable into dummy variable\n","\n","y = np.array(data['CR (%)']) #output feature\n","X = data.drop(['CR (%)', 'ECR PY (%)', 'PDOs PY (%)', 'POHs PY (%)', 'V'], axis=1) #input feature - axis=1 refers to the column\n","\n","X_list = list(X.columns) # Saving feature names for later use\n","\n","from sklearn.preprocessing import StandardScaler #standardscaler for normalization (Jinesh et al., 2023)\n","scaler = StandardScaler()\n","\n","y = y.reshape(-1, 1) #normalizing y\n","scaler.fit(y)\n","y = scaler.transform(y)\n","\n","scaler.fit(X) #normalizing X\n","X = scaler.transform(X)\n","\n","X = np.array(X) # Convert to numpy array\n","\n","# Using Skicit-learn to split data into training and testing sets\n","from sklearn.model_selection import train_test_split\n","\n","# Split the data into training and testing sets\n","train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42)\n","print('Training X Shape:', train_X.shape)\n","print('Training y Shape:', train_y.shape)\n","print('Testing X Shape:', test_X.shape)\n","print('Testing y Shape:', test_y.shape)\n","\n","#imputation for missing value using kNN algo\n","from sklearn.impute import KNNImputer\n","\n","imputer = KNNImputer(n_neighbors=10) #create an instance of KNNImputer class, k is desired number of neighbours\n","\n","#perform imputation on on X because y no missing values\n","imp_train_X = imputer.fit_transform(train_X)\n","imp_test_X = imputer.fit_transform(test_X)\n","\n","model = DecisionTreeRegressor(criterion=\"squared_error\", max_depth=None, max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2)\n","model.fit(imp_train_X, train_y)\n","preds_val = model.predict(imp_test_X)\n","\n","score = model.score(imp_train_X,train_y)\n","print(\"Training score: \", score)\n","\n","pred = model.predict(imp_test_X)\n","\n","print(\"Mean Absolute Error: \" + str(mean_absolute_error(test_y, pred)))\n","print(\"MSE: \" + str(mean_squared_error(pred, test_y)))\n","\n","RMSE = sqrt(mean_squared_error(pred, test_y))\n","\n","print(\"RMSE: \" + str(RMSE))\n","print(\"R2 score: \" + str(r2_score(test_y, pred)))\n","\n"],"metadata":{"id":"Hxjt0qcuaP1b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706101449602,"user_tz":-540,"elapsed":2866,"user":{"displayName":"Muhd Harussani","userId":"10681559320848216583"}},"outputId":"ef25dd6b-9886-4c4d-8f8d-f584ca5e0d09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training X Shape: (312, 30)\n","Training y Shape: (312, 1)\n","Testing X Shape: (134, 30)\n","Testing y Shape: (134, 1)\n","Training score:  0.9999978961344894\n","Mean Absolute Error: 0.16013297575966134\n","MSE: 0.09128333743769917\n","RMSE: 0.3021313248203489\n","R2 score: 0.9128263327112014\n"]}]},{"cell_type":"code","source":["#gridsearch next!\n","\n","import pandas as pd\n","import numpy as np\n","from math import sqrt\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.metrics import r2_score\n","\n","path = \"/content/drive/MyDrive/dataset/raw data.csv\"\n","data = pd.read_csv(path)\n","\n","data = pd.get_dummies(data) #convert categorical variable into dummy variable\n","\n","y = np.array(data['PDOs PY (%)']) #output feature\n","X = data.drop(['CR (%)', 'PDOs PY (%)', 'I (A)'], axis=1) #input feature - axis=1 refers to the column\n","\n","X_list = list(X.columns) # Saving feature names for later use\n","\n","from sklearn.preprocessing import StandardScaler #standardscaler for normalization (Jinesh et al., 2023)\n","scaler = StandardScaler()\n","\n","y = y.reshape(-1, 1) #normalizing y\n","scaler.fit(y)\n","y = scaler.transform(y)\n","\n","scaler.fit(X) #normalizing X\n","X = scaler.transform(X)\n","\n","X = np.array(X) # Convert to numpy array\n","\n","# Using Skicit-learn to split data into training and testing sets\n","from sklearn.model_selection import train_test_split\n","\n","# Split the data into training and testing sets\n","train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42)\n","print('Training X Shape:', train_X.shape)\n","print('Training y Shape:', train_y.shape)\n","print('Testing X Shape:', test_X.shape)\n","print('Testing y Shape:', test_y.shape)\n","\n","#imputation for missing value using kNN algo\n","from sklearn.impute import KNNImputer\n","\n","imputer = KNNImputer(n_neighbors=10) #create an instance of KNNImputer class, k is desired number of neighbours\n","\n","#perform imputation on on X because y no missing values\n","imp_train_X = imputer.fit_transform(train_X)\n","imp_test_X = imputer.fit_transform(test_X)\n","\n","#hyperparamter optimization using gridsearch\n","from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n","random_cv = GridSearchCV(\n","            estimator=DecisionTreeRegressor(),\n","            param_grid={'max_depth': [None, 5, 10],\n","                        'min_samples_split': [2, 5, 10],\n","                        'min_samples_leaf': [1, 5, 10],\n","                        'max_leaf_nodes': [None, 20, 50],\n","                        'criterion': ['friedman_mse', 'absolute_error', 'squared_error']}, #, 'poisson'\n","            cv=3, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n","#This includes 3-fold validation (cv=3) and uses mean scare error as the metric for evaluation\n","\n","random_cv.fit(imp_train_X, train_y)\n","\n","# use the best parameters\n","best_params = random_cv.best_params_\n","best_score = random_cv.best_score_\n","print('Best hyperparameters:', best_params)\n","\n","# using the best parameters run XGBoost\n","model = DecisionTreeRegressor(**best_params)\n","model.fit(imp_train_X, train_y)\n","\n","score = model.score(imp_train_X,train_y)\n","print(\"Training score: \", score)\n","\n","pred = model.predict(imp_test_X)\n","\n","print(\"Mean Absolute Error: \" + str(mean_absolute_error(test_y, pred)))\n","print(\"MSE: \" + str(mean_squared_error(pred, test_y)))\n","\n","RMSE = sqrt(mean_squared_error(pred, test_y))\n","\n","print(\"RMSE: \" + str(RMSE))\n","print(\"R2 score: \" + str(r2_score(test_y, pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RWytJGO8WuWP","executionInfo":{"status":"ok","timestamp":1705304076643,"user_tz":-540,"elapsed":7033,"user":{"displayName":"Muhd Harussani","userId":"10681559320848216583"}},"outputId":"594879d2-c03d-4322-f01f-fb508e2971a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training X Shape: (312, 30)\n","Training y Shape: (312, 1)\n","Testing X Shape: (134, 30)\n","Testing y Shape: (134, 1)\n","Best hyperparameters: {'criterion': 'absolute_error', 'max_depth': 10, 'max_leaf_nodes': 50, 'min_samples_leaf': 1, 'min_samples_split': 2}\n","Training score:  0.680243490118653\n","Mean Absolute Error: 0.2529876359135884\n","MSE: 0.4449198916432459\n","RMSE: 0.6670231567518822\n","R2 score: 0.6049778550726286\n"]}]},{"cell_type":"code","source":["############improved version always second (PDOs PY)\n","\n","import pandas as pd\n","import numpy as np\n","from math import sqrt\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.metrics import r2_score\n","\n","path = \"/content/drive/MyDrive/dataset/raw data.csv\"\n","data = pd.read_csv(path)\n","\n","data = pd.get_dummies(data) #convert categorical variable into dummy variable\n","\n","y = np.array(data['ECR PY (%)']) #output feature\n","X = data.drop(['CR (%)', 'ECR PY (%)', 'PDOs PY (%)', 'POHs PY (%)', 'V'], axis=1) #input feature - axis=1 refers to the column\n","\n","X_list = list(X.columns) # Saving feature names for later use\n","\n","from sklearn.preprocessing import StandardScaler #standardscaler for normalization (Jinesh et al., 2023)\n","scaler = StandardScaler()\n","\n","y = y.reshape(-1, 1) #normalizing y\n","scaler.fit(y)\n","y = scaler.transform(y)\n","\n","scaler.fit(X) #normalizing X\n","X = scaler.transform(X)\n","\n","X = np.array(X) # Convert to numpy array\n","\n","# Using Skicit-learn to split data into training and testing sets\n","from sklearn.model_selection import train_test_split\n","\n","# Split the data into training and testing sets\n","train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42)\n","print('Training X Shape:', train_X.shape)\n","print('Training y Shape:', train_y.shape)\n","print('Testing X Shape:', test_X.shape)\n","print('Testing y Shape:', test_y.shape)\n","\n","#imputation for missing value using kNN algo\n","from sklearn.impute import KNNImputer\n","\n","imputer = KNNImputer(n_neighbors=10) #create an instance of KNNImputer class, k is desired number of neighbours\n","\n","#perform imputation on on X because y no missing values\n","imp_train_X = imputer.fit_transform(train_X)\n","imp_test_X = imputer.fit_transform(test_X)\n","\n","model = DecisionTreeRegressor(criterion=\"absolute_error\", max_depth=10, max_leaf_nodes=50, min_samples_leaf=1, min_samples_split=2)\n","model.fit(imp_train_X, train_y)\n","preds_val = model.predict(imp_test_X)\n","\n","score = model.score(imp_train_X,train_y)\n","print(\"Training score: \", score)\n","\n","pred = model.predict(imp_test_X)\n","\n","print(\"Mean Absolute Error: \" + str(mean_absolute_error(test_y, pred)))\n","print(\"MSE: \" + str(mean_squared_error(pred, test_y)))\n","\n","RMSE = sqrt(mean_squared_error(pred, test_y))\n","\n","print(\"RMSE: \" + str(RMSE))\n","print(\"R2 score: \" + str(r2_score(test_y, pred)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JR-MzN6LC6TC","executionInfo":{"status":"ok","timestamp":1714976181830,"user_tz":-540,"elapsed":351,"user":{"displayName":"Muhd Harussani","userId":"10681559320848216583"}},"outputId":"a03c0808-140c-4623-8b17-9e8bd66e1787"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training X Shape: (312, 30)\n","Training y Shape: (312, 1)\n","Testing X Shape: (134, 30)\n","Testing y Shape: (134, 1)\n","Training score:  0.6806977834260924\n","Mean Absolute Error: 0.24625488380417768\n","MSE: 0.44192680904077103\n","RMSE: 0.6647757584635371\n","R2 score: 0.6077365280751355\n"]}]}]}